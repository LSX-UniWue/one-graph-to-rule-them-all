{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpy as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "from utils import network_to_pyg\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79962eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "def calculate_metrics(cv):\n",
    "    return {'F1-score': np.mean(cv['test_f1_macro']), 'Accuracy':np.mean(cv['test_accuracy']), \n",
    "            'Precision': np.mean(cv['test_precision_macro']), 'Recall':np.mean(cv['test_recall_macro'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load the data set\n",
    "    df = pd.read_csv('new_data.csv')\n",
    "\n",
    "    # load the labels\n",
    "    with open('book_labels.json') as f:\n",
    "        labelsGB = json.load(f)\n",
    "\n",
    "    # change to scalar\n",
    "    labelsGB = {k: 0 if v=='lotr' else 1 if v =='hobbit' else 2 for k,v in labelsGB.items()}\n",
    "\n",
    "    # load the empty network\n",
    "    one = pp.Network(directed=False)\n",
    "\n",
    "    # add the nodes\n",
    "    for i in range(df.shape[0]):\n",
    "        one.add_edge(df.loc[i, 'v'], df.loc[i, 'w'])\n",
    "\n",
    "    # add the classes as node features\n",
    "    for v in one.nodes:\n",
    "        v['y'] = torch.tensor([labelsGB[v.uid]])\n",
    "\n",
    "    # add the node2vec embeddings as node features\n",
    "    df = pd.read_csv('node2vec-p1q1.csv')\n",
    "    for v in one.nodes:\n",
    "        v['node2vec-p1q1'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the node2vec embeddings as node features\n",
    "    df = pd.read_csv('node2vec-p1q4.csv')\n",
    "    for v in one.nodes:\n",
    "        v['node2vec-p1q4'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the node2vec embeddings as node features\n",
    "    df = pd.read_csv('node2vec-p4q1.csv')\n",
    "    for v in one.nodes:\n",
    "        v['node2vec-p4q1'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the word2vec as node features\n",
    "    df = pd.read_csv('words_and_vectors.csv')\n",
    "    for v in one.nodes:\n",
    "        v['word2vec'] = torch.from_numpy(df[df['words'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the Laplacian Embeddings as node features\n",
    "    df = pd.read_csv('LE_embedding.csv')\n",
    "    for v in one.nodes:\n",
    "        v['le'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # adding the weights\n",
    "    df = pd.read_csv('new_data.csv').loc[:, ['v', 'w']]\n",
    "    weights = df.value_counts().to_dict()\n",
    "    for e in one.edges:\n",
    "        e['weight'] = weights[(e.v.uid, e.w.uid)]\n",
    "\n",
    "    # convert the network to PyG data set\n",
    "    data = network_to_pyg(one)\n",
    "\n",
    "    return data, one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ec3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, one = load_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d76cd7",
   "metadata": {},
   "source": [
    "# Random Walk methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d068b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "# initialize the model\n",
    "model = Node2Vec(data.edge_index, embedding_dim=20, walk_length=8,\n",
    "                 context_size=4, walks_per_node=3,\n",
    "                 num_negative_samples=1, p=1, q=1, sparse=True)\n",
    "\n",
    "# data loader to speed the train \n",
    "loader = model.loader(batch_size=32, shuffle=True, num_workers=4)  \n",
    "# initzialize the optimizer \n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "\n",
    "losses = []\n",
    "def train():\n",
    "    # put model in train model\n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        # set the gradients to 0\n",
    "        optimizer.zero_grad()  \n",
    "        # compute the loss for the batch\n",
    "        loss = model.loss(pos_rw, neg_rw)  \n",
    "        loss.backward()\n",
    "        # optimize the parameters\n",
    "        optimizer.step()  \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# train for n epochs\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "        \n",
    "# get the embeddings from the trained model\n",
    "X_node2vec = model(torch.arange(data.num_nodes)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embeddings from the trained model\n",
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in model(torch.arange(data.num_nodes))], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('node2vec-p1q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cade5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('node2vec-p1q4.csv')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, tol=1e-8, penalty='none')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], [v['y'].item() for v in one.nodes], \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "logreg.fit(X_train,y_train )\n",
    "lr_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "lr_p1q4 = calculate_metrics(y_test, lr_pred)\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "lr_p1q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f45129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('node2vec-p4q1.csv')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, tol=1e-8, penalty='none')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], [v['y'].item() for v in one.nodes], \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "logreg.fit(X_train,y_train )\n",
    "lr_pred = logreg.predict(X_test)\n",
    "    \n",
    "lr_p4q1 = calculate_metrics(y_test, lr_pred)\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "lr_p4q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4aec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('node2vec-p1q1.csv')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, tol=1e-8, penalty='none')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], [v['y'].item() for v in one.nodes], \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "logreg.fit(X_train,y_train )\n",
    "lr_pred = logreg.predict(X_test)\n",
    "    \n",
    "lr_p1q1 = calculate_metrics(y_test, lr_pred)\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "lr_p1q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1b8f4",
   "metadata": {},
   "source": [
    "# MessagePassing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2caaa",
   "metadata": {},
   "source": [
    "# GCN with deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = list(range(df.shape[0]))\n",
    "\n",
    "df = pd.read_csv('node2vec-p1q4.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, _, y_train, y_test = train_test_split(df.iloc[:, :-1], mask, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = torch.tensor([False]*df.shape[0])\n",
    "for i in y_train:\n",
    "    train_mask[i] = True\n",
    "        \n",
    "test_mask = torch.from_numpy(np.invert(train_mask).detach().numpy()).bool()\n",
    "\n",
    "X = torch.from_numpy(df.iloc[:,:-1].values)\n",
    "y = torch.tensor([v['y'].item() for v in one.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66326385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, hidden_dim=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gcn1 = torch_geometric.nn.GCNConv(num_features, 10) \n",
    "        self.gcn2 = torch_geometric.nn.GCNConv(10, 20)\n",
    "        self.lin = torch.nn.Linear(20, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.lin(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd29c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(num_features=data.node2vec11.shape[1], num_classes=3, hidden_dim=512)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "zeros_loss_list = []\n",
    "for epoch in range(5000):\n",
    "    output = model(data.node2vec11, data.edge_index)\n",
    "    loss = loss_function(output[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    zeros_loss_list.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ ,pred = model(data.node2vec11, data.edge_index).max(dim=1)\n",
    "gcn_p1q1 = calculate_metrics(y.numpy()[test_mask], pred.numpy()[test_mask])\n",
    "print(confusion_matrix(y.numpy()[test_mask], pred.numpy()[test_mask]))\n",
    "gcn_p1q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(zeros_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model.gcn1(data.node2vec11, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)\n",
    "x = model.gcn2(x, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b15a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(x.detach().numpy())\n",
    "\n",
    "colors = {}\n",
    "for v in one.nodes:\n",
    "    index = one.nodes.index[v.uid]\n",
    "    if v['y'] == 1:\n",
    "        colors[index] = 'blue'\n",
    "    elif v['y'] == 0:\n",
    "        colors[index] = 'red'\n",
    "    else:\n",
    "        colors[index] = 'green'\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors.values(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in x], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('GCN_deepwalk_embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f32aef",
   "metadata": {},
   "source": [
    "# GAT with deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gcn1 = torch_geometric.nn.GATConv(num_features, 5, heads=2) \n",
    "        self.gcn2 = torch_geometric.nn.GATConv(5*2, 20, heads=1) \n",
    "        self.lin = torch.nn.Linear(20, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.lin(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(num_features=data.node2vec11.shape[1], num_classes=3, hidden_dim=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "zeros_loss_list = []\n",
    "for epoch in range(5000):\n",
    "    output = model(data.node2vec11, data.edge_index)\n",
    "    loss = loss_function(output[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    zeros_loss_list.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6481714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ ,pred = model(data.node2vec11, data.edge_index).max(dim=1)\n",
    "    \n",
    "gat_p1q1 = calculate_metrics(y.numpy()[test_mask], pred.numpy()[test_mask])\n",
    "print(confusion_matrix(y.numpy()[test_mask], pred.numpy()[test_mask]))\n",
    "gat_p1q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d2ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(zeros_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model.gcn1(data.node2vec11, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)\n",
    "x = model.gcn2(x, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(x.detach().numpy())\n",
    "\n",
    "colors = {}\n",
    "for v in one.nodes:\n",
    "    index = one.nodes.index[v.uid]\n",
    "    if v['y'] == 1:\n",
    "        colors[index] = 'blue'\n",
    "    elif v['y'] == 0:\n",
    "        colors[index] = 'red'\n",
    "    else:\n",
    "        colors[index] = 'green'\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors.values(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ecd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in x], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('GAT_deepwalk_embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840add4e",
   "metadata": {},
   "source": [
    "# GCN with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = list(range(one.number_of_nodes()))\n",
    "\n",
    "X = torch.eye(one.number_of_nodes())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, _, y_train, y_test = train_test_split(X, mask, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = torch.tensor([False]*df.shape[0])\n",
    "for i in y_train:\n",
    "    train_mask[i] = True\n",
    "        \n",
    "test_mask = torch.from_numpy(np.invert(train_mask).detach().numpy()).bool()\n",
    "\n",
    "y = torch.tensor([v['y'].item() for v in one.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576adbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(num_features=data.ohe.shape[1], num_classes=3, hidden_dim=512)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "zeros_loss_list = []\n",
    "for epoch in range(5000):\n",
    "    output = model(data.ohe, data.edge_index)\n",
    "    loss = loss_function(output[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    zeros_loss_list.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a347a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ ,pred = model(data.ohe, data.edge_index).max(dim=1)\n",
    "gcn_onehot = calculate_metrics(y.numpy()[test_mask], pred.numpy()[test_mask])\n",
    "print(confusion_matrix(y.numpy()[test_mask], pred.numpy()[test_mask]))\n",
    "gcn_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f0381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(zeros_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model.gcn1(data.ohe, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)\n",
    "x = model.gcn2(x, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac32e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(x.detach().numpy())\n",
    "\n",
    "colors = {}\n",
    "for v in one.nodes:\n",
    "    index = one.nodes.index[v.uid]\n",
    "    if v['y'] == 1:\n",
    "        colors[index] = 'blue'\n",
    "    elif v['y'] == 0:\n",
    "        colors[index] = 'red'\n",
    "    else:\n",
    "        colors[index] = 'green'\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors.values(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in x], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('GCN_onehot_embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479d751",
   "metadata": {},
   "source": [
    "# GAT with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52852237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(num_features=data.ohe.shape[1], num_classes=3, hidden_dim=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "zeros_loss_list = []\n",
    "for epoch in range(5000):\n",
    "    output = model(data.ohe, data.edge_index)\n",
    "    loss = loss_function(output[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    zeros_loss_list.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ ,pred = model(data.ohe, data.edge_index).max(dim=1)\n",
    "gat_onehot = calculate_metrics(y.numpy()[test_mask], pred.numpy()[test_mask])\n",
    "print(confusion_matrix(y.numpy()[test_mask], pred.numpy()[test_mask]))\n",
    "gat_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a8b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(zeros_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa67cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model.gcn1(data.ohe, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)\n",
    "x = model.gcn2(x, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f309904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(x.detach().numpy())\n",
    "\n",
    "colors = {}\n",
    "for v in one.nodes:\n",
    "    index = one.nodes.index[v.uid]\n",
    "    if v['y'] == 1:\n",
    "        colors[index] = 'blue'\n",
    "    elif v['y'] == 0:\n",
    "        colors[index] = 'red'\n",
    "    else:\n",
    "        colors[index] = 'green'\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors.values(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in x], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('GAT_onehot_embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ea30c",
   "metadata": {},
   "source": [
    "# Message Passing methods with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c48d86",
   "metadata": {},
   "source": [
    "# GCN with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = list(range(one.number_of_nodes()))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, _, y_train, y_test = train_test_split(mask, mask, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = torch.tensor([False]*one.number_of_nodes())\n",
    "for i in y_train:\n",
    "    train_mask[i] = True\n",
    "        \n",
    "test_mask = torch.from_numpy(np.invert(train_mask).detach().numpy()).bool()\n",
    "\n",
    "y = torch.tensor([v['y'].item() for v in one.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(num_features=data.word2vec.shape[1], num_classes=3, hidden_dim=512)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "zeros_loss_list = []\n",
    "for epoch in range(5000):\n",
    "    output = model(data.word2vec, data.edge_index)\n",
    "    loss = loss_function(output[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    zeros_loss_list.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6875040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ ,pred = model(data.word2vec, data.edge_index).max(dim=1)\n",
    "gcn_word = calculate_metrics(y.numpy()[test_mask], pred.numpy()[test_mask])\n",
    "print(confusion_matrix(y.numpy()[test_mask], pred.numpy()[test_mask]))\n",
    "gcn_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(zeros_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model.gcn1(data.word2vec, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)\n",
    "x = model.gcn2(x, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(x.detach().numpy())\n",
    "\n",
    "colors = {}\n",
    "for v in one.nodes:\n",
    "    index = one.nodes.index[v.uid]\n",
    "    if v['y'] == 1:\n",
    "        colors[index] = 'blue'\n",
    "    elif v['y'] == 0:\n",
    "        colors[index] = 'red'\n",
    "    else:\n",
    "        colors[index] = 'green'\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors.values(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in x], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('GCN_word_embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250f081",
   "metadata": {},
   "source": [
    "# GAT with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(num_features=data.word2vec.shape[1], num_classes=3, hidden_dim=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "zeros_loss_list = []\n",
    "for epoch in range(2000):\n",
    "    output = model(data.word2vec, data.edge_index)\n",
    "    loss = loss_function(output[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    zeros_loss_list.append(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ ,pred = model(data.word2vec, data.edge_index).max(dim=1)\n",
    "gat_word = calculate_metrics(y.numpy()[test_mask], pred.numpy()[test_mask])\n",
    "print(confusion_matrix(y.numpy()[test_mask], pred.numpy()[test_mask]))\n",
    "gat_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(zeros_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b656e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model.gcn1(data.word2vec, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)\n",
    "x = model.gcn2(x, data.edge_index)\n",
    "x = torch.nn.functional.selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(x.detach().numpy())\n",
    "\n",
    "colors = {}\n",
    "for v in one.nodes:\n",
    "    index = one.nodes.index[v.uid]\n",
    "    if v['y'] == 1:\n",
    "        colors[index] = 'blue'\n",
    "    elif v['y'] == 0:\n",
    "        colors[index] = 'red'\n",
    "    else:\n",
    "        colors[index] = 'green'\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors.values(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20022724",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in x], \n",
    "                          columns=list(range(20)))\n",
    "embeddings['characters'] = pd.Series([i.uid for i in one.nodes])\n",
    "embeddings.to_csv('GAT_word_embedding.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a82bd241c82d99c2c9c10f28c0c3038e3b687ac4586f020f679a8286ab2478eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
