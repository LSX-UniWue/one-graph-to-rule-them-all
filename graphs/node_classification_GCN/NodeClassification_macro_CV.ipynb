{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpy as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.model_selection import cross_validate\n",
    "import json\n",
    "from utils import network_to_pyg\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load the data set\n",
    "    df = pd.read_csv('new_data.csv')\n",
    "\n",
    "    # load the labels\n",
    "    with open('book_labels.json') as f:\n",
    "        labelsGB = json.load(f)\n",
    "\n",
    "    # change to scalar\n",
    "    labelsGB = {k: 0 if v=='lotr' else 1 if v =='hobbit' else 2 for k,v in labelsGB.items()}\n",
    "\n",
    "    # load the empty network\n",
    "    one = pp.Network(directed=False)\n",
    "\n",
    "    # add the nodes\n",
    "    for i in range(df.shape[0]):\n",
    "        one.add_edge(df.loc[i, 'v'], df.loc[i, 'w'])\n",
    "\n",
    "    # add the classes as node features\n",
    "    for v in one.nodes:\n",
    "        v['y'] = torch.tensor([labelsGB[v.uid]])\n",
    "\n",
    "    # add the node2vec embeddings as node features\n",
    "    df = pd.read_csv('node2vec-p1q1.csv')\n",
    "    for v in one.nodes:\n",
    "        v['node2vec-p1q1'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the node2vec embeddings as node features\n",
    "    df = pd.read_csv('node2vec-p1q4.csv')\n",
    "    for v in one.nodes:\n",
    "        v['node2vec-p1q4'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the node2vec embeddings as node features\n",
    "    df = pd.read_csv('node2vec-p4q1.csv')\n",
    "    for v in one.nodes:\n",
    "        v['node2vec-p4q1'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the word2vec as node features\n",
    "    df = pd.read_csv('words_and_vectors.csv')\n",
    "    for v in one.nodes:\n",
    "        v['word2vec'] = torch.from_numpy(df[df['words'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # add the Laplacian Embeddings as node features\n",
    "    df = pd.read_csv('LE_embedding.csv')\n",
    "    for v in one.nodes:\n",
    "        v['le'] = torch.from_numpy(df[df['characters'] == v.uid].iloc[:, :-1].values).squeeze()\n",
    "\n",
    "    # adding the weights\n",
    "    df = pd.read_csv('new_data.csv').loc[:, ['v', 'w']]\n",
    "    weights = df.value_counts().to_dict()\n",
    "    for e in one.edges:\n",
    "        e['weight'] = weights[(e.v.uid, e.w.uid)]\n",
    "\n",
    "    # convert the network to PyG data set\n",
    "    data = network_to_pyg(one)\n",
    "\n",
    "    return data, one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, one = load_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d76cd7",
   "metadata": {},
   "source": [
    "# Random Walk methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d068b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import Node2Vec\n",
    "\n",
    "# # initialize the model\n",
    "# model = Node2Vec(data.edge_index, embedding_dim=20, walk_length=8,\n",
    "#                  context_size=4, walks_per_node=3,\n",
    "#                  num_negative_samples=1, p=1, q=1, sparse=True)\n",
    "\n",
    "# # data loader to speed the train \n",
    "# loader = model.loader(batch_size=32, shuffle=True, num_workers=4)  \n",
    "# # initzialize the optimizer \n",
    "# optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "\n",
    "# def train():\n",
    "#     # put model in train model\n",
    "#     model.train()  \n",
    "#     total_loss = 0\n",
    "#     for pos_rw, neg_rw in loader:\n",
    "#         # set the gradients to 0\n",
    "#         optimizer.zero_grad()  \n",
    "#         # compute the loss for the batch\n",
    "#         loss = model.loss(pos_rw, neg_rw)  \n",
    "#         loss.backward()\n",
    "#         # optimize the parameters\n",
    "#         optimizer.step()  \n",
    "#         total_loss += loss.item()\n",
    "#     return total_loss / len(loader)\n",
    "\n",
    "# # train for n epochs\n",
    "# for epoch in range(1, 201):\n",
    "#     loss = train()\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "        \n",
    "# # get the embeddings from the trained model\n",
    "# X_node2vec = model(torch.arange(n.number_of_nodes())).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the embeddings from the trained model\n",
    "# embeddings = pd.DataFrame([tensor.detach().numpy() for tensor in model(torch.arange(n.number_of_nodes()))], \n",
    "#                           columns=list(range(128)))\n",
    "# embeddings['characters'] = pd.Series([i.uid for i in n.nodes])\n",
    "# embeddings.to_csv('node2vec-p1q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "def calculate_metrics(cv):\n",
    "    return {'F1-score': np.mean(cv['test_f1_macro']), 'Accuracy':np.mean(cv['test_accuracy']), \n",
    "            'Precision': np.mean(cv['test_precision_macro']), 'Recall':np.mean(cv['test_recall_macro'])}\n",
    "\n",
    "def calculate_metrics_std(cv):\n",
    "    return {'F1-score': np.std(cv['test_f1_macro']), 'Accuracy':np.std(cv['test_accuracy']), \n",
    "            'Precision': np.std(cv['test_precision_macro']), 'Recall':np.std(cv['test_recall_macro'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cade5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('node2vec-p1q4.csv')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, tol=1e-8, penalty='none')\n",
    "\n",
    "\n",
    "scores = cross_validate(logreg, df.iloc[:, :-1], [v['y'].item() for v in one.nodes], cv=10,\n",
    "                        scoring=('f1_macro', 'accuracy', 'precision_macro', 'recall_macro'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "    \n",
    "lr_p1q4 = calculate_metrics(scores)\n",
    "print(lr_p1q4)\n",
    "calculate_metrics_std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f45129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('node2vec-p4q1.csv')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, tol=1e-8, penalty='none')\n",
    "\n",
    "scores = cross_validate(logreg, df.iloc[:, :-1], [v['y'].item() for v in one.nodes], cv=10,\n",
    "                        scoring=('f1_macro', 'accuracy', 'precision_macro', 'recall_macro'),\n",
    "                        return_train_score=True)\n",
    "    \n",
    "lr_p4q1 = calculate_metrics(scores)\n",
    "print(lr_p4q1)\n",
    "calculate_metrics_std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4aec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('node2vec-p1q1.csv')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, tol=1e-8, penalty='none')\n",
    "\n",
    "scores = cross_validate(logreg, df.iloc[:, :-1], [v['y'].item() for v in one.nodes], cv=10,\n",
    "                        scoring=('f1_macro', 'accuracy', 'precision_macro', 'recall_macro'),\n",
    "                        return_train_score=True)\n",
    "    \n",
    "lr_p1q1 = calculate_metrics(scores)\n",
    "lr_p1q1\n",
    "print(lr_p1q1)\n",
    "calculate_metrics_std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf91258",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_walk_table = pd.DataFrame({'Node2vec-p1q4': lr_p1q4,\n",
    "                                 'Node2vec-p4q1': lr_p4q1,\n",
    "                                 'DeepWalk': lr_p1q1})\n",
    "\n",
    "random_walk_table.to_csv('CV_NodeClassification_node2vec_deepwalk.csv')\n",
    "random_walk_table.style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1b8f4",
   "metadata": {},
   "source": [
    "# MessagePassing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2caaa",
   "metadata": {},
   "source": [
    "# GCN with deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true):\n",
    "    return {'F1-score':f1_score(y_pred, y_true, average=\"macro\"), 'Accuracy':accuracy_score(y_pred, y_true), \n",
    "            'Precision':precision_score(y_pred, y_true, average=\"macro\"), 'Recall':recall_score(y_pred, y_true,average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def k_fold(dataset, folds, y ):\n",
    "    skf = StratifiedKFold(folds, shuffle=False)\n",
    "\n",
    "    test_indices, train_indices = [], []\n",
    "    for _, idx in skf.split(torch.zeros(len(dataset)), y):\n",
    "        test_indices.append(torch.from_numpy(idx).to(torch.long))\n",
    "\n",
    "\n",
    "    for i in range(folds):\n",
    "        train_mask = torch.ones(len(dataset), dtype=torch.bool)\n",
    "        train_mask[test_indices[i]] = 0\n",
    "        train_indices.append(train_mask.nonzero(as_tuple=False).view(-1))\n",
    "\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66326385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, hidden_dim=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gcn1 = torch_geometric.nn.GCNConv(num_features, hidden_dim) \n",
    "        self.gcn2 = torch_geometric.nn.GCNConv(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weights):\n",
    "        \n",
    "        x = self.gcn1(x, edge_index, edge_weights)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.gcn2(x, edge_index, edge_weights)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        \n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd29c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.node2vec11\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "losses = []\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GCN(num_features=X.shape[1], num_classes=3, hidden_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(5000):\n",
    "        output = model(X.float(), data.edge_index, data.edge_weights)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index, data.edge_weights).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gcn_p1q1 = {k:np.mean(v) for k,v in scores.items()}\n",
    "gcn_p1q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85357e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f32aef",
   "metadata": {},
   "source": [
    "# GAT with deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, hidden_dim=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gcn1 = torch_geometric.nn.GATConv(num_features, int(hidden_dim/2), heads=2) \n",
    "        self.gcn2 = torch_geometric.nn.GATConv(hidden_dim, num_classes, heads=1) \n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        \n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f77e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.node2vec11\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "losses = []\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GAT(num_features=X.shape[1], num_classes=3, hidden_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(5000):\n",
    "        output = model(X, data.edge_index)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X, data.edge_index).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gat_p1q1 = {k:np.mean(v) for k,v in scores.items()}\n",
    "gat_p1q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840add4e",
   "metadata": {},
   "source": [
    "# GCN with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.ohe\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "losses = []\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GCN(num_features=X.shape[1], num_classes=3, hidden_dim=8)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(5000):\n",
    "        output = model(X.float(), data.edge_index, data.edge_weights)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index, data.edge_weights).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gcn_onehot = {k:np.mean(v) for k,v in scores.items()}\n",
    "gcn_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed029d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479d751",
   "metadata": {},
   "source": [
    "# GAT with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.ohe\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "losses = []\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GAT(num_features=X.shape[1], num_classes=3, hidden_dim=64)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(5000):\n",
    "        output = model(X.float(), data.edge_index)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    print(pred[test_indices])\n",
    "    print(y.numpy()[test_indices])\n",
    "    \n",
    "gat_onehot = {k:np.mean(v) for k,v in scores.items()}\n",
    "gat_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dbda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_table = pd.DataFrame({'GCN_DeepWalk':gcn_p1q1,\n",
    "                         'GCN_OneHotEncoding':gcn_onehot,\n",
    "                         'GAT_DeepWalk':gat_p1q1,\n",
    "                         'GAT_OneHotEncoding':gat_onehot})\n",
    "\n",
    "gnn_table.to_csv('CV_NodeClassification_gcn_gat.csv')\n",
    "gnn_table.style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ea30c",
   "metadata": {},
   "source": [
    "# Message Passing methods with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c48d86",
   "metadata": {},
   "source": [
    "# GCN with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.word2vec\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GCN(num_features=X.shape[1], num_classes=3, hidden_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    for epoch in range(5000):\n",
    "        output = model(X.float(), data.edge_index, data.edge_weights)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index, data.edge_weights).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gcn_word = {k:np.mean(v) for k,v in scores.items()}\n",
    "gcn_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250f081",
   "metadata": {},
   "source": [
    "# GAT with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.word2vec\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GAT(num_features=X.shape[1], num_classes=3, hidden_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(2000):\n",
    "        output = model(X.float(), data.edge_index)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gat_word = {k:np.mean(v) for k,v in scores.items()}\n",
    "gat_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_table = pd.DataFrame({'GCN_Word2Vec':gcn_word,\n",
    "                         'GAT_Word2Vec':gat_word})\n",
    "\n",
    "gnn_table.to_csv('CV_NodeClassification_gcn_gat_word2vec.csv')\n",
    "gnn_table.style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae537b4",
   "metadata": {},
   "source": [
    "# GCN with LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484af086",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.le\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GCN(num_features=X.shape[1], num_classes=3, hidden_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    for epoch in range(5000):\n",
    "        output = model(X.float(), data.edge_index, data.edge_weights)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index, data.edge_weights).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gcn_le = {k:np.mean(v) for k,v in scores.items()}\n",
    "gcn_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93405be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8638eba",
   "metadata": {},
   "source": [
    "# GAT with LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'F1-score':[], 'Accuracy':[], 'Precision':[], 'Recall':[]}\n",
    "k = 10\n",
    "X = data.le\n",
    "y = data.y.squeeze().long()\n",
    "indices = k_fold(X,k,y)\n",
    "for train_indices, test_indices in zip(*indices):\n",
    "    model = GAT(num_features=X.shape[1], num_classes=3, hidden_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(2000):\n",
    "        output = model(X.float(), data.edge_index)\n",
    "        loss = loss_function(output[train_indices], y[train_indices])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    _ ,pred = model(X.float(), data.edge_index).max(dim=1)\n",
    "    cm = calculate_metrics(y.numpy()[test_indices], pred.numpy()[test_indices])\n",
    "    scores['F1-score'].append(cm['F1-score'])\n",
    "    scores['Accuracy'].append(cm['Accuracy'])\n",
    "    scores['Precision'].append(cm['Precision'])\n",
    "    scores['Recall'].append(cm['Recall'])\n",
    "    \n",
    "gat_le = {k:np.mean(v) for k,v in scores.items()}\n",
    "gat_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:np.std(v) for k,v in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_table = pd.DataFrame({'GCN_LE':gcn_le,\n",
    "                         'GAT_LE':gat_le})\n",
    "\n",
    "gnn_table.to_csv('CV_NodeClassification_gcn_gat_le.csv')\n",
    "gnn_table.style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822044f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = pd.read_csv('CV_NodeClassification_node2vec_deepwalk.csv', index_col=0)\n",
    "gnn = pd.read_csv('CV_NodeClassification_gcn_gat.csv', index_col=0)\n",
    "word = pd.read_csv('CV_NodeClassification_gcn_gat_word2vec.csv', index_col=0)\n",
    "le = pd.read_csv('CV_NodeClassification_gcn_gat_le.csv', index_col=0)\n",
    "rw_gnn = pd.concat([rw,gnn,word,le],axis=1)\n",
    "rw_gnn.to_csv('CV_NodeClassification_GNN_RW_Word_LE.csv')\n",
    "rw_gnn.T.apply(lambda x: round(x*100, 2)).style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('teaching')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a82bd241c82d99c2c9c10f28c0c3038e3b687ac4586f020f679a8286ab2478eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
